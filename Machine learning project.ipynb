{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mora</th>\n",
       "      <th>atraso</th>\n",
       "      <th>vivienda</th>\n",
       "      <th>edad</th>\n",
       "      <th>dias_lab</th>\n",
       "      <th>exp_sf</th>\n",
       "      <th>nivel_ahorro</th>\n",
       "      <th>ingreso</th>\n",
       "      <th>linea_sf</th>\n",
       "      <th>deuda_sf</th>\n",
       "      <th>score</th>\n",
       "      <th>zona</th>\n",
       "      <th>clasif_sbs</th>\n",
       "      <th>nivel_educ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>235</td>\n",
       "      <td>FAMILIAR</td>\n",
       "      <td>30</td>\n",
       "      <td>3748</td>\n",
       "      <td>93.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>214</td>\n",
       "      <td>Lima</td>\n",
       "      <td>4</td>\n",
       "      <td>UNIVERSITARIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>FAMILIAR</td>\n",
       "      <td>32</td>\n",
       "      <td>4598</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12</td>\n",
       "      <td>900.0</td>\n",
       "      <td>1824.67</td>\n",
       "      <td>1933.75</td>\n",
       "      <td>175</td>\n",
       "      <td>La Libertad</td>\n",
       "      <td>1</td>\n",
       "      <td>TECNICA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>FAMILIAR</td>\n",
       "      <td>26</td>\n",
       "      <td>5148</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2797.38</td>\n",
       "      <td>188.29</td>\n",
       "      <td>187</td>\n",
       "      <td>Lima</td>\n",
       "      <td>0</td>\n",
       "      <td>UNIVERSITARIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>FAMILIAR</td>\n",
       "      <td>36</td>\n",
       "      <td>5179</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>187</td>\n",
       "      <td>Ancash</td>\n",
       "      <td>0</td>\n",
       "      <td>TECNICA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>FAMILIAR</td>\n",
       "      <td>46</td>\n",
       "      <td>3960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>11010.65</td>\n",
       "      <td>189</td>\n",
       "      <td>Lima</td>\n",
       "      <td>0</td>\n",
       "      <td>TECNICA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mora  atraso  vivienda  edad  dias_lab  exp_sf  nivel_ahorro  ingreso  \\\n",
       "0     0     235  FAMILIAR    30      3748    93.0             5   3500.0   \n",
       "1     0      18  FAMILIAR    32      4598     9.0            12    900.0   \n",
       "2     0       0  FAMILIAR    26      5148     8.0             2   2400.0   \n",
       "3     0       0  FAMILIAR    36      5179    20.0            12   2700.0   \n",
       "4     0       0  FAMILIAR    46      3960     NaN             1   3100.0   \n",
       "\n",
       "   linea_sf  deuda_sf  score         zona  clasif_sbs     nivel_educ  \n",
       "0       NaN      0.00    214         Lima           4  UNIVERSITARIA  \n",
       "1   1824.67   1933.75    175  La Libertad           1        TECNICA  \n",
       "2   2797.38    188.29    187         Lima           0  UNIVERSITARIA  \n",
       "3       NaN      0.00    187       Ancash           0        TECNICA  \n",
       "4   2000.00  11010.65    189         Lima           0        TECNICA  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "mydataML=pd.read_csv(\"C:/Users/OCTAVIO/Documents/Academic/Python/Machine Learning 1/data (1).csv\")\n",
    "mydataML.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000.0, 123.7, 2400.0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats=mydataML.describe()\n",
    "dum_vivienda=pd.get_dummies(mydataML.vivienda,prefix=\"dum\")\n",
    "dum_zona=pd.get_dummies(mydataML.zona,prefix=\"dum\")\n",
    "dum_niveleduc=pd.get_dummies(mydataML.nivel_educ,prefix=\"dum\")\n",
    "mydataML=pd.concat([mydataML,dum_niveleduc,dum_vivienda,dum_zona],axis=1)\n",
    "np.max(mydataML.ingreso),np.min(mydataML.ingreso),np.median(mydataML.ingreso)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mora                    0\n",
       "atraso                  0\n",
       "vivienda                0\n",
       "edad                    0\n",
       "dias_lab                0\n",
       "exp_sf               1830\n",
       "nivel_ahorro            0\n",
       "ingreso                 0\n",
       "linea_sf             1127\n",
       "deuda_sf              461\n",
       "score                   0\n",
       "zona                    0\n",
       "clasif_sbs              0\n",
       "nivel_educ              0\n",
       "dum_SECUNDARIA          0\n",
       "dum_SIN EDUCACION       0\n",
       "dum_TECNICA             0\n",
       "dum_UNIVERSITARIA       0\n",
       "dum_ALQUILADA           0\n",
       "dum_FAMILIAR            0\n",
       "dum_PROPIA              0\n",
       "dum_Amazonas            0\n",
       "dum_Ancash              0\n",
       "dum_Apurimac            0\n",
       "dum_Arequipa            0\n",
       "dum_Ayacucho            0\n",
       "dum_Cajamarca           0\n",
       "dum_Callao              0\n",
       "dum_Cuzco               0\n",
       "dum_Huancavelica        0\n",
       "dum_Huanuco             0\n",
       "dum_Ica                 0\n",
       "dum_Junin               0\n",
       "dum_La Libertad         0\n",
       "dum_Lambayeque          0\n",
       "dum_Lima                0\n",
       "dum_Loreto              0\n",
       "dum_Madre de Dios       0\n",
       "dum_Moquegua            0\n",
       "dum_Pasco               0\n",
       "dum_Piura               0\n",
       "dum_Puno                0\n",
       "dum_San Martin          0\n",
       "dum_Tacna               0\n",
       "dum_Tumbes              0\n",
       "dum_Ucayali             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentilemydat=np.nanpercentile(mydataML.ingreso,range(0,101))\n",
    "np.sum(mydataML.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deuda_sf    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Llenado de NaNs mediante asignaci√≥n de promedios\n",
    "group_exp_sf=pd.DataFrame(mydataML.groupby([\"nivel_educ\"])[\"exp_sf\"].mean()) \n",
    "group_linea_sf=pd.DataFrame(mydataML.groupby([\"zona\"])[\"linea_sf\"].mean()) \n",
    "group_deuda_sf=pd.DataFrame(mydataML.groupby([\"vivienda\"])[\"deuda_sf\"].mean())\n",
    "group_deuda_sf.loc[\"ALQUILADA\",\"deuda_sf\"]\n",
    "group_deuda_sf.loc[\"FAMILIAR\",\"deuda_sf\"]\n",
    "educ={}\n",
    "zonasperu={}\n",
    "viv={}\n",
    "\n",
    "for j in group_exp_sf.index:\n",
    "    educ[j]=pd.DataFrame(mydataML.loc[mydataML[\"nivel_educ\"]==j,\"exp_sf\"])\n",
    "    educ[j][\"exp_sf\"].fillna(np.mean(educ[j][\"exp_sf\"]),inplace=True)\n",
    "\n",
    "group_linea_sf.drop([\"Huancavelica\"],inplace=True)\n",
    "\n",
    "for zonas in group_linea_sf.index:\n",
    "    zonasperu[zonas]=pd.DataFrame(mydataML.loc[mydataML[\"zona\"]==zonas,\"linea_sf\"])\n",
    "    zonasperu[zonas][\"linea_sf\"].fillna(np.mean(zonasperu[zonas][\"linea_sf\"]),inplace=True)\n",
    "\n",
    "for tviv in group_deuda_sf.index:\n",
    "    viv[tviv]=pd.DataFrame(mydataML.loc[mydataML[\"vivienda\"]==tviv,\"deuda_sf\"])\n",
    "    viv[tviv][\"deuda_sf\"].fillna(np.mean(viv[tviv][\"deuda_sf\"]),inplace=True)\n",
    "\n",
    "np.sum(viv[\"FAMILIAR\"].isnull()),\n",
    "np.sum(viv[\"PROPIA\"].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazando en la data original\n",
    "\n",
    "for n in group_exp_sf.index:\n",
    "    mydataML.loc[mydataML[\"nivel_educ\"]==n,\"exp_sf\"]=educ[n][\"exp_sf\"]\n",
    "\n",
    "for m in group_linea_sf.index:\n",
    "    mydataML.loc[mydataML[\"zona\"]==m,\"linea_sf\"]=zonasperu[m][\"linea_sf\"]\n",
    "\n",
    "for cv in group_deuda_sf.index:\n",
    "    mydataML.loc[mydataML[\"vivienda\"]==cv,\"deuda_sf\"]=viv[cv][\"deuda_sf\"]\n",
    "\n",
    "np.sum(mydataML.isnull())\n",
    "mydataML.linea_sf.fillna(np.mean(mydataML.linea_sf),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tratamiento de outliers LI->2  LS->98\n",
    "\n",
    "percentilemydat=np.nanpercentile(mydataML.ingreso,range(0,101))\n",
    "\n",
    "mydataML[\"ingreso\"]=np.where(mydataML[\"ingreso\"]<=percentilemydat[1],percentilemydat[1],\n",
    "         np.where(mydataML[\"ingreso\"]>=percentilemydat[98],percentilemydat[98],mydataML.ingreso))\n",
    "\n",
    "X=mydataML.loc[:,['mora', 'atraso', 'edad', 'dias_lab', 'exp_sf',\n",
    "       'nivel_ahorro','linea_sf', 'deuda_sf', 'score',\n",
    "       'clasif_sbs', 'dum_SECUNDARIA', 'dum_SIN EDUCACION',\n",
    "       'dum_TECNICA', 'dum_UNIVERSITARIA', 'dum_ALQUILADA', 'dum_FAMILIAR',\n",
    "       'dum_PROPIA', 'dum_Amazonas', 'dum_Ancash', 'dum_Apurimac',\n",
    "       'dum_Arequipa', 'dum_Ayacucho', 'dum_Cajamarca', 'dum_Callao',\n",
    "       'dum_Cuzco', 'dum_Huancavelica', 'dum_Huanuco', 'dum_Ica', 'dum_Junin',\n",
    "       'dum_La Libertad', 'dum_Lambayeque', 'dum_Lima', 'dum_Loreto',\n",
    "       'dum_Madre de Dios', 'dum_Moquegua', 'dum_Pasco', 'dum_Piura',\n",
    "       'dum_Puno', 'dum_San Martin', 'dum_Tacna', 'dum_Tumbes', 'dum_Ucayali']]\n",
    "\n",
    "Y=pd.DataFrame(mydataML.loc[:,'ingreso'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9958870293151003, 0.3464905968286356)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, Ytrain, Ytest=train_test_split(X, Y, test_size=0.3, random_state=5)\n",
    "\n",
    "##################\n",
    "#√Årbol de decisi√≥n\n",
    "##################\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "#Objeto\n",
    "arb_reg=DecisionTreeRegressor(max_depth=20)\n",
    "\n",
    "#Entrenamiento\n",
    "arb_reg.fit(Xtrain,Ytrain.ingreso)\n",
    "\n",
    "#Predicci√≥n\n",
    "pr_arb_train=arb_reg.predict(Xtrain)\n",
    "pr_arb_test=arb_reg.predict(Xtest)\n",
    "arb_reg.score(Xtrain,Ytrain.ingreso),arb_reg.score(Xtest,Ytest.ingreso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4262.3536604864785, 4262.353660486477],\n",
       " [4273.648746031742, 4497.3265961215475])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calibraci√≥n\n",
    "[np.mean(Ytrain.ingreso),np.mean(arb_reg.predict(Xtrain))], [np.mean(Ytest.ingreso),np.mean(arb_reg.predict(Xtest))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>linea_sf</th>\n",
       "      <td>0.360363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_sf</th>\n",
       "      <td>0.119481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dias_lab</th>\n",
       "      <td>0.114430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deuda_sf</th>\n",
       "      <td>0.084680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.082058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          importancia\n",
       "linea_sf     0.360363\n",
       "exp_sf       0.119481\n",
       "dias_lab     0.114430\n",
       "deuda_sf     0.084680\n",
       "score        0.082058"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importancia de las variables tratadas\n",
    "impor=pd.DataFrame(arb_reg.feature_importances_)\n",
    "impor.index=Xtrain.columns\n",
    "impor.columns=['importancia']\n",
    "impor.sort_values('importancia',ascending=False,inplace=True)\n",
    "\n",
    "#Nuevas variables\n",
    "Xtrain.columns\n",
    "Xtrain_2=Xtrain.loc[:,['mora', 'atraso', 'edad', 'dias_lab', 'exp_sf', 'nivel_ahorro',\n",
    "       'linea_sf', 'deuda_sf', 'score', 'clasif_sbs', 'dum_SECUNDARIA',\n",
    "       'dum_SIN EDUCACION', 'dum_TECNICA', 'dum_UNIVERSITARIA',\n",
    "       'dum_ALQUILADA', 'dum_FAMILIAR', 'dum_PROPIA', 'dum_Amazonas']]\n",
    "\n",
    "Xtest_2=Xtest.loc[:,['mora', 'atraso', 'edad', 'dias_lab', 'exp_sf', 'nivel_ahorro',\n",
    "       'linea_sf', 'deuda_sf', 'score', 'clasif_sbs', 'dum_SECUNDARIA',\n",
    "       'dum_SIN EDUCACION', 'dum_TECNICA', 'dum_UNIVERSITARIA',\n",
    "       'dum_ALQUILADA', 'dum_FAMILIAR', 'dum_PROPIA', 'dum_Amazonas']]\n",
    "impor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Optimizando profundidad con las nuevas variables\n",
    "from sklearn.model_selection import GridSearchCV # Librer√≠a\n",
    "# Generando objetos\n",
    "space=np.array(range(1,50)) # Valores a probar\n",
    "param={'max_depth':space} # Objeto a optimizar\n",
    "arbol_param=DecisionTreeRegressor() # Objeto (√°rbol de decisi√≥n)\n",
    "# Aplicaci√≥n del Algoritmo\n",
    "arbol_grid=GridSearchCV(arbol_param,param,cv=6) #Objeto\n",
    "arbol_grid.fit(Xtrain_2,Ytrain.ingreso) #entrenamiento\n",
    "# Revisando par√°metros √≥ptimos\n",
    "arbol_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5181037279212066, 0.3420784279707718)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# R cuadrados\n",
    "arbol_grid.score(Xtrain_2,Ytrain.ingreso), arbol_grid.score(Xtest_2,Ytest.ingreso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5181037279212064, 0.34222218491714307)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reentrenando Decision Tree Regressor con la profundidad optimizada y las nuevas variables\n",
    "\n",
    "arb_reg2=DecisionTreeRegressor(max_depth=6)\n",
    "#Entrenamiento\n",
    "arb_reg2.fit(Xtrain_2,Ytrain.ingreso)\n",
    "\n",
    "#Predicci√≥n\n",
    "pr_arb_train2=arb_reg2.predict(Xtrain_2)\n",
    "pr_arb_test2=arb_reg2.predict(Xtest_2)\n",
    "\n",
    "#Performance R cuadrado\n",
    "arb_reg2.score(Xtrain_2,Ytrain.ingreso) , arb_reg2.score(Xtest_2,Ytest.ingreso) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4262.3536604864785, 4262.353660486478],\n",
       " [4273.648746031742, 4359.471558238525])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calibraci√≥n\n",
    "[np.mean(Ytrain.ingreso),np.mean(arb_reg2.predict(Xtrain_2))] , [np.mean(Ytest.ingreso),np.mean(arb_reg2.predict(Xtest_2))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.08470770970561481, -0.09031768834311049)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########################\n",
    "#Support Vector Regressor\n",
    "##########################\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "# Objeto\n",
    "SVRe=SVR()\n",
    "# Entrenando \n",
    "SVRe.fit(Xtrain_2,Ytrain.ingreso)\n",
    "\n",
    "#Predicci√≥n \n",
    "prob=SVRe.predict(Xtrain_2)\n",
    "\n",
    "# Perfomance R cuadrado\n",
    "SVRe.score(Xtrain_2,Ytrain.ingreso), SVRe.score(Xtest_2,Ytest.ingreso) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4262.3536604864785, 2414.103957163793],\n",
       " [4273.648746031742, 2423.08557046502])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.mean(Ytrain.ingreso),np.mean(prob)], [np.mean(Ytest.ingreso),np.mean(SVRe.predict(Xtest_2))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5712243678352475, 0.4252807656784374)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########################\n",
    "# Random Forest Regressor\n",
    "##########################\n",
    "\n",
    "# Libreria\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Objeto\n",
    "rf_reg=RandomForestRegressor(max_depth=6,n_estimators=10,random_state=5)\n",
    "# Entrenando\n",
    "rf_reg.fit(Xtrain_2,Ytrain.ingreso)\n",
    "\n",
    "# Predicci√≥n\n",
    "rf_reg.predict(Xtrain_2)\n",
    "rf_reg.predict(Xtest_2)\n",
    "\n",
    "# Performance: R cuadrado \n",
    "rf_reg.score(Xtrain_2,Ytrain.ingreso) , rf_reg.score(Xtest_2,Ytest.ingreso) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4262.3536604864785, 4247.207314048219],\n",
       " [4273.648746031742, 4320.116084348399])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.mean(Ytrain.ingreso),np.mean(rf_reg.predict(Xtrain_2))] , [np.mean(Ytest.ingreso),np.mean(rf_reg.predict(Xtest_2))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4089957680128373, 0.3856049361399404)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################\n",
    "# Regresi√≥n Lineal\n",
    "##################\n",
    "\n",
    "# Libreria\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lineal=LinearRegression()\n",
    "lineal.fit(Xtrain_2,Ytrain.ingreso)\n",
    "\n",
    "#Performance\n",
    "lineal.score(Xtrain_2,Ytrain.ingreso) , lineal.score(Xtest_2,Ytest.ingreso) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4262.3536604864785, 4262.353660486478],\n",
       " [4273.648746031742, 4358.238501893564])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicci√≥n\n",
    "lineal.predict(Xtrain_2)\n",
    "lineal.predict(Xtest_2)\n",
    "\n",
    "#Calibraci√≥n\n",
    "[np.mean(Ytrain.ingreso),np.mean(lineal.predict(Xtrain_2))] , [np.mean(Ytest.ingreso),np.mean(lineal.predict(Xtest_2))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.09909617172063957, -0.08470770970561481]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################\n",
    "#ESTABILIDAD DE LOS ALGORITMOS \n",
    "##############################\n",
    "\n",
    "#Nota: Solo los algoritmos de √°rboles de regresi√≥n cuentan con las nuevas variables y la profundidad optimizada\n",
    "\n",
    "Xtrain_2.columns\n",
    "Xtrain.columns\n",
    "bst_rc=[]\n",
    "bst_1={} #Diccionario para variables de Xtrain 1\n",
    "bst_2={} #Diccionario para variables de Xtrain 2\n",
    "\n",
    "for v in Xtrain.columns:\n",
    "    bst_1[v]=[]\n",
    "\n",
    "for bs in Xtrain_2.columns:\n",
    "    bst_2[bs]=[]\n",
    "\n",
    "\n",
    "##Support Vector Regressor\n",
    "\n",
    "for i in range(200):\n",
    "    sample=np.random.choice(Xtrain.index,size=4000) # Sub-muestra\n",
    "    muestra_x=Xtrain_2.loc[sample,:] # Generando X\n",
    "    muestra_y=Ytrain.loc[sample,'ingreso'] # Generando y\n",
    "    mod=SVR() # Objeto de la regresi√≥n\n",
    "    mod.fit(muestra_x,muestra_y) # Entrenando\n",
    "    # Almacenando resultados\n",
    "    bst_rc.append(mod.score(muestra_x,muestra_y))\n",
    "\n",
    "\n",
    "# Comparando\n",
    "[np.mean(bst_rc),SVRe.score(Xtrain_2,Ytrain.ingreso)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5119657745846321, 0.5181037279212064]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Decision Tree Regressor\n",
    "for i in range(2000):\n",
    "    sample=np.random.choice(Xtrain_2.index,size=4500) # Sub-muestra\n",
    "    muestra_x=Xtrain_2.loc[sample,:] # Generando X\n",
    "    muestra_y=Ytrain.loc[sample,\"ingreso\"] # Generando y\n",
    "    mod=DecisionTreeRegressor(max_depth=6) # Objeto de la regresi√≥n\n",
    "    mod.fit(muestra_x,muestra_y) # Entrenando\n",
    "    # Almacenando resultados\n",
    "    bst_rc.append(mod.score(muestra_x,muestra_y))\n",
    "\n",
    "\n",
    "# Comparando\n",
    "[np.mean(bst_rc),arb_reg2.score(Xtrain_2,Ytrain.ingreso)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5482276546345755, 0.5712243678352475]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Random Forest Regressor\n",
    "for i in range(1000):\n",
    "    sample=np.random.choice(Xtrain_2.index,size=4500) # Sub-muestra\n",
    "    muestra_x=Xtrain_2.loc[sample,:] # Generando X\n",
    "    muestra_y=Ytrain.loc[sample,\"ingreso\"] # Generando y\n",
    "    mod=RandomForestRegressor(max_depth=6,n_estimators=10,random_state=5) # Objeto de la regresi√≥n\n",
    "    mod.fit(muestra_x,muestra_y) # Entrenando\n",
    "    # Almacenando resultados\n",
    "    bst_rc.append(mod.score(muestra_x,muestra_y))\n",
    "    \n",
    "# Comparando\n",
    "[np.mean(bst_rc),rf_reg.score(Xtrain_2,Ytrain.ingreso)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.48237897919982947, 0.4089957680128373]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Linear Regression\n",
    "for i in range(3000):\n",
    "    sample=np.random.choice(Xtrain_2.index,size=4500) # Sub-muestra\n",
    "    muestra_x=Xtrain_2.loc[sample,:] # Generando X\n",
    "    muestra_y=Ytrain.loc[sample,\"ingreso\"] # Generando y\n",
    "    mod=LinearRegression()# Objeto de la regresi√≥n\n",
    "    mod.fit(muestra_x,muestra_y) # Entrenando\n",
    "    # Almacenando resultados\n",
    "    bst_rc.append(mod.score(muestra_x,muestra_y))\n",
    "    \n",
    "    \n",
    "# Comparando\n",
    "[np.mean(bst_rc),lineal.score(Xtrain_2,Ytrain.ingreso)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "#An√°lisis de calibraci√≥n\n",
    "########################\n",
    "np.sum(mydataML.isnull())\n",
    "\n",
    "#El algoritmo seleccionado es el de regresi√≥n lineal\n",
    "import scipy.stats as st\n",
    "alpha=0.05\n",
    "st.norm.ppf(1-alpha/2)\n",
    "\n",
    "#Calibraci√≥n global\n",
    "Ytrain['ing_inter']=pd.cut(Ytrain.ingreso,bins=np.percentile(Ytrain.ingreso,range(0,101,20)))\n",
    "lin_predic_train=pd.DataFrame(lineal.predict(Xtrain_2))\n",
    "lin_predic_train.columns=[\"predict\"]\n",
    "lin_predic_train[\"predic_cat\"]=pd.cut(lin_predic_train.predict,bins=np.percentile(lin_predic_train.predict,range(0,101,20)))\n",
    "\n",
    "lin_predic_test=pd.DataFrame(lineal.predict(Xtest_2))\n",
    "lin_predic_test.columns=[\"predict\"]\n",
    "\n",
    "cal={'ingreso':[np.mean(Ytrain.ingreso)],'predic':[np.mean(lin_predic_train[\"predict\"])]}\n",
    "\n",
    "cal_global=pd.DataFrame(cal)\n",
    "cal_global[\"LS\"]=cal_global.predic+st.norm.ppf(1-alpha/2)*(np.var(lin_predic_train[\"predict\"])/len(lin_predic_train[\"predict\"]))**0.5\n",
    "cal_global[\"LI\"]=cal_global.predic-st.norm.ppf(1-alpha/2)*(np.var(lin_predic_train[\"predict\"])/len(lin_predic_train[\"predict\"]))**0.5\n",
    "cal_global['Calibracion']=np.where((cal_global.ingreso>=cal_global.LI)&(cal_global.ingreso<=cal_global.LS),'Calibrado','Descalibrado')\n",
    "\n",
    "\n",
    "lin_predic_train.predict.index=Ytrain.index\n",
    "lin_predic_test.index=Ytest.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniendo predicciones para medir calibraci√≥n\n",
    "mydataML_unif=pd.concat([lin_predic_train.predict,lin_predic_test.predict])\n",
    "mydataML_unif=pd.DataFrame(mydataML_unif)\n",
    "mydataML_unif.columns=[\"predict\"]\n",
    "data_2=pd.concat([mydataML,mydataML_unif],axis=1)\n",
    "\n",
    "##Calibraci√≥n por nivel educativo\n",
    "part1_niv_edu=data_2.groupby(['nivel_educ'])['ingreso'].agg(media_ingreso='mean',n='count')\n",
    "part2_niv_edu=data_2.groupby(['nivel_educ'])['predict'].agg(media_predict='mean')\n",
    "cal_niveduc=pd.concat([part2_niv_edu,part1_niv_edu],axis=1)\n",
    "\n",
    "secu=pd.DataFrame(data_2.loc[data_2.nivel_educ==\"SECUNDARIA\",\"predict\"])\n",
    "sin_educ=pd.DataFrame(data_2.loc[data_2.nivel_educ==\"SIN EDUCACION\",\"predict\"])\n",
    "tecni=pd.DataFrame(data_2.loc[data_2.nivel_educ==\"TECNICA\",\"predict\"])\n",
    "uni=pd.DataFrame(data_2.loc[data_2.nivel_educ==\"UNIVERSITARIA\",\"predict\"])\n",
    "len(secu)\n",
    "len(sin_educ)\n",
    "len(data_2.loc[data_2.nivel_educ==\"SECUNDARIA\",\"predict\"])\n",
    "\n",
    "var_secu=pd.DataFrame(np.var(secu))\n",
    "var_sin_educ=pd.DataFrame(np.var(sin_educ))\n",
    "var_tecni=pd.DataFrame(np.var(tecni))\n",
    "var_uni=pd.DataFrame(np.var(uni))\n",
    "\n",
    "var_total=pd.concat([var_secu,var_sin_educ,var_tecni,var_uni])\n",
    "var_total.index=cal_niveduc.index\n",
    "cal_niveduc[\"var_tot\"]=var_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OCTAVIO\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\fromnumeric.py:3472: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Calibraci√≥n\n",
       "Calibrado    1.0\n",
       "Name: n_pct, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for u in cal_niveduc.index:\n",
    "    cal_niveduc.loc[cal_niveduc.index==u,[\"LS\"]]=(np.mean(data_2.loc[data_2.nivel_educ==u,\"predict\"]))+st.norm.ppf(1-alpha/2)*(cal_niveduc.loc[cal_niveduc.index==u,\"var_tot\"]/len(data_2.loc[data_2.nivel_educ==u,\"predict\"]))**0.5\n",
    "    cal_niveduc.loc[cal_niveduc.index==u,[\"LI\"]]=(np.mean(data_2.loc[data_2.nivel_educ==u,\"predict\"]))-st.norm.ppf(1-alpha/2)*(cal_niveduc.loc[cal_niveduc.index==u,\"var_tot\"]/len(data_2.loc[data_2.nivel_educ==u,\"predict\"]))**0.5\n",
    "\n",
    "np.var(np.array([4,3,5,8,4,5]))\n",
    "np.var(secu)\n",
    "np.mean(secu)\n",
    "cal_niveduc['Calibraci√≥n']=np.where((cal_niveduc.media_ingreso>=cal_niveduc.LI)&(cal_niveduc.media_ingreso<=cal_niveduc.LS),'Calibrado','Descalibrado')\n",
    "cal_niveduc['n_pct']=cal_niveduc.n/np.sum(cal_niveduc.n)\n",
    "cal_niveduc['amplitud']=cal_niveduc.LS-cal_niveduc.LI\n",
    "### Midiendo porcentaje de calibraci√≥n\n",
    "cal_niveduc.groupby(['Calibraci√≥n'])['n_pct'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Calibraci√≥n\n",
       "Calibrado    1.0\n",
       "Name: n_pct, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Calibraci√≥n por tipo de vivienda\n",
    "part1_tip_viv=data_2.groupby(['vivienda'])['ingreso'].agg(media_ingreso='mean',n='count')\n",
    "part2_tip_viv=data_2.groupby(['vivienda'])['predict'].agg(media_predict='mean')\n",
    "cal_tip_viv=pd.concat([part2_tip_viv,part1_tip_viv],axis=1)\n",
    "\n",
    "cal_tip_viv[\"LS\"]=\"\"\n",
    "cal_tip_viv[\"LI\"]=\"\"\n",
    "\n",
    "var_2={}\n",
    "viv={}\n",
    "\n",
    "for l√± in cal_tip_viv.index:\n",
    "    var_2[l√±]=pd.DataFrame(np.var(pd.DataFrame(data_2.loc[data_2.vivienda==l√±,\"predict\"])))\n",
    "    var_2[l√±].columns=[\"var_total\"]\n",
    "\n",
    "vari_total=[]\n",
    "\n",
    "for t in var_2.keys():\n",
    "    vari_total.append(var_2[t][\"var_total\"])\n",
    "\n",
    "vari_total=pd.DataFrame(vari_total)\n",
    "vari_total.index=cal_tip_viv.index\n",
    "cal_tip_viv[\"var_total\"]=vari_total.predict\n",
    "\n",
    "\n",
    "for jp in cal_tip_viv.index:\n",
    "    cal_tip_viv.loc[cal_tip_viv.index==jp,[\"LS\"]]=(np.mean(data_2.loc[data_2.vivienda==jp,\"predict\"]))+st.norm.ppf(1-alpha/2)*(cal_tip_viv.loc[cal_tip_viv.index==jp,\"var_total\"]/len(data_2.loc[data_2.vivienda==jp,\"predict\"]))**0.5\n",
    "    cal_tip_viv.loc[cal_tip_viv.index==jp,[\"LI\"]]=(np.mean(data_2.loc[data_2.vivienda==jp,\"predict\"]))-st.norm.ppf(1-alpha/2)*(cal_tip_viv.loc[cal_tip_viv.index==jp,\"var_total\"]/len(data_2.loc[data_2.vivienda==jp,\"predict\"]))**0.5\n",
    "\n",
    "cal_tip_viv['Calibraci√≥n']=np.where((cal_tip_viv.media_ingreso>=cal_tip_viv.LI)&(cal_tip_viv.media_ingreso<=cal_tip_viv.LS),'Calibrado','Descalibrado')\n",
    "cal_tip_viv['n_pct']=cal_tip_viv.n/np.sum(cal_tip_viv.n)\n",
    "cal_tip_viv['amplitud']=cal_tip_viv.LS-cal_tip_viv.LI\n",
    "\n",
    "### Midiendo porcentaje de calibraci√≥n\n",
    "cal_tip_viv.groupby(['Calibraci√≥n'])['n_pct'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Calibraci√≥n\n",
       "Calibrado       0.539469\n",
       "Descalibrado    0.460531\n",
       "Name: n_pct, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Calibraci√≥n por edad\n",
    "part1_edad=data_2.groupby(['edad'])['ingreso'].agg(media_ingreso='mean',n='count')\n",
    "part2_edad=data_2.groupby(['edad'])['predict'].agg(media_predict='mean')\n",
    "cal_edad=pd.concat([part2_edad,part1_edad],axis=1)\n",
    "\n",
    "cal_edad[\"LS\"]=\"\"\n",
    "cal_edad[\"LI\"]=\"\"\n",
    "\n",
    "var_3={}\n",
    "edad={}\n",
    "\n",
    "for lg in cal_edad.index:\n",
    "    var_3[lg]=pd.DataFrame(np.var(pd.DataFrame(data_2.loc[data_2.edad==lg,\"predict\"])))\n",
    "    var_3[lg].columns=[\"var_total\"]\n",
    "\n",
    "vari_total_2=[]\n",
    "\n",
    "for tg in cal_edad.index:\n",
    "    vari_total_2.append(var_3[tg][\"var_total\"])\n",
    "\n",
    "vari_total_2=pd.DataFrame(vari_total_2)\n",
    "vari_total_2.index=cal_edad.index\n",
    "cal_edad[\"var_total\"]=vari_total_2.predict\n",
    "\n",
    "for pk in cal_edad.index:\n",
    "    cal_edad.loc[cal_edad.index==pk,[\"LS\"]]=(np.mean(data_2.loc[data_2.edad==pk,\"predict\"]))+st.norm.ppf(1-alpha/2)*(cal_edad.loc[cal_edad.index==pk,\"var_total\"]/len(data_2.loc[data_2.edad==pk,\"predict\"]))**0.5\n",
    "    cal_edad.loc[cal_edad.index==pk,[\"LI\"]]=(np.mean(data_2.loc[data_2.edad==pk,\"predict\"]))-st.norm.ppf(1-alpha/2)*(cal_edad.loc[cal_edad.index==pk,\"var_total\"]/len(data_2.loc[data_2.edad==pk,\"predict\"]))**0.5\n",
    "\n",
    "cal_edad['Calibraci√≥n']=np.where((cal_edad.media_ingreso>=cal_edad.LI)&(cal_edad.media_ingreso<=cal_edad.LS),'Calibrado','Descalibrado')\n",
    "cal_edad['n_pct']=cal_edad.n/np.sum(cal_edad.n)\n",
    "cal_edad['amplitud']=cal_edad.LS-cal_edad.LI\n",
    "\n",
    "### Midiendo porcentaje de calibraci√≥n\n",
    "cal_edad.groupby(['Calibraci√≥n'])['n_pct'].sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
